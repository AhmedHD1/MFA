{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all packages needed\n",
    "#install = \"sudo apt-get install python3-pip python3-tk python3-pil python3-pil.imagetk python3-pandas python3-numpy python3-matplotlib python3-scipy python3-sklearn python3-sklearn-lib python3-textgrid\"\n",
    "#import os\n",
    "#os.system(install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the duration of each cue\n",
    "# import all libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import textgrid\n",
    "import time\n",
    "import subprocess\n",
    "import shutil\n",
    "import sys\n",
    "from tqdm.notebook import tqdm \n",
    "root_directory = \"C:/Users/Nabiya/Box/Academic-Duke/CoganLab/test_4/\"\n",
    "pattern = re.compile(r'^D\\d+$')\n",
    "\n",
    "def calculate_dur(wav):\n",
    "    a = read(wav)\n",
    "    fs = a[0]\n",
    "    time = (np.array(a[1],dtype=float)).shape[0] / fs\n",
    "    return time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_text_dict ={}\n",
    "speech_text_dict['hut'] = 'hut'\n",
    "speech_text_dict['heat'] = 'heat'\n",
    "speech_text_dict['hoot'] = 'hoot'\n",
    "speech_text_dict['hot'] = 'hot'\n",
    "speech_text_dict['mice'] = 'there was once a house that was overrun with mice'\n",
    "speech_text_dict['dog'] = 'the dog was very proud of the bell'\n",
    "speech_text_dict['fame'] = 'notoriety is often mistaken for fame'\n",
    "speech_text_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_dict = {}\n",
    "duration_dict['heat'] = calculate_dur('SentenceRep_Stim/heat.wav')\n",
    "duration_dict['hut'] = calculate_dur('SentenceRep_Stim/hut.wav')\n",
    "duration_dict['hoot'] = calculate_dur('SentenceRep_Stim/hoot.wav')\n",
    "duration_dict['hot'] = calculate_dur('SentenceRep_Stim/hot.wav')\n",
    "duration_dict['mice'] = calculate_dur('SentenceRep_Stim/HouseMice3Secs.wav')\n",
    "duration_dict['dog'] = calculate_dur('SentenceRep_Stim/DogBell18Sec.wav')\n",
    "duration_dict['fame'] = calculate_dur('SentenceRep_Stim/NotorietyFame.wav')\n",
    "duration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all these print statements to a file\n",
    "with open('unique_values.txt', 'w') as f:\n",
    "    for item in os.listdir(root_directory):\n",
    "        patient_path = os.path.join(root_directory, item)\n",
    "\n",
    "        if os.path.isdir(patient_path) and pattern.match(item):\n",
    "            cond_path = os.path.join(patient_path, 'condition_events.txt')\n",
    "            cue_path = os.path.join(patient_path, 'cue_events.txt')\n",
    "            condition_file = open(cond_path, 'r')\n",
    "            condition_lines = condition_file.readlines()\n",
    "            cue_file = open(cue_path, 'r')\n",
    "            cue_lines = cue_file.readlines()\n",
    "            condition_file.close()\n",
    "            cue_file.close()\n",
    "            condition_values = set(tuple(line.strip().split('\\t')[2].split('_')[1:]) for line in condition_lines)\n",
    "            cue_values = set(tuple(line.strip().split('\\t')[2].split('_')[1:]) for line in cue_lines)\n",
    "            f.write(f'Patient {item} has the following unique values for conditions: {condition_values}\\n')\n",
    "            f.write(f'Patient {item} has the following unique values for cues: {cue_values}\\n')\n",
    "            f.write('\\n')\n",
    "            print(f'Patient {item} has the following unique values for conditions: {condition_values}')\n",
    "            print(f'Patient {item} has the following unique values for cues: {cue_values}')\n",
    "            print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judging from the unique values of condition and cue files, you can exclude trials that are noisy or have no stimulus etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(patient_path):\n",
    "    '''\n",
    "    This function takes in the file path, path to condition events, cue event\n",
    "    Return a file with the annotated events\n",
    "\n",
    "    We assume that we get the conditions from the task for free\n",
    "    and we assume that we get the cue start for free too\n",
    "    Cue end will be modified using duration_dict\n",
    "\n",
    "    '''\n",
    "    cond_path = os.path.join(patient_path, 'condition_events.txt')\n",
    "    cue_path = os.path.join(patient_path, 'cue_events.txt')\n",
    "    output_path = os.path.join(patient_path, 'annotated_events.txt')\n",
    "    condition_file = open(cond_path, 'r')\n",
    "    condition_lines = condition_file.readlines()\n",
    "    cue_file = open(cue_path, 'r')\n",
    "    cue_lines = cue_file.readlines()\n",
    "    with open(output_path, 'w') as file:\n",
    "        for i in range(len(condition_lines)):\n",
    "        # cue_s is cue start, cue_e is cue end, cond_s is condition start, cond_e is condition end\n",
    "            cue_s1, cue_e1, cue= cue_lines[i].strip().split('\\t')\n",
    "            if i == len(condition_lines)-1:\n",
    "                cue_s2, cue_e2, cue_2 = f\"{float(cue_e1) + 6}\", None, None\n",
    "            else:\n",
    "                cue_s2, cue_e2, cue_2 = cue_lines[i+1].strip().split('\\t')\n",
    "            # what should i do if cue.split('_')[2] is noisy\n",
    "            # i think it is better to not include them in the annotated events- personal opinion\n",
    "            if len(cue.split('_')) == 3 and ((cue.split('_')[2] == 'noisy') or (cue.split('_')[2] == 'noStim')):\n",
    "                continue\n",
    "            cue = cue.split('_')[1]\n",
    "            \n",
    "            cue_e1 = float(cue_s1) + float(duration_dict[cue])\n",
    "            cue_text = speech_text_dict[cue]\n",
    "            cond_s, cond_e, cond = condition_lines[i].strip().split('\\t')\n",
    "            # we are only writing the text if condition is listen, otherwise skip\n",
    "            if cond.endswith(':=:'):\n",
    "                continue\n",
    "            elif cond.endswith('Listen'):\n",
    "                \n",
    "                # add buffer to cue_s1 and subtract buffer from cue_s2\n",
    "                cue_e1 = float(cue_e1) + 0.25\n",
    "                cue_s2 = float(cue_s2) - 0.25\n",
    "                file.write(f'{cue_e1}\\t{cue_s2}\\t{cue_text}\\n')\n",
    "        # print length of condition lines and cue lines just for fun\n",
    "    len_cue, len_cond = len(cue_lines), len(condition_lines)\n",
    "    patient_name = patient_path.split('/')[-1]\n",
    "    print(f'Patient {patient_name} has {len_cue} cue lines and {len_cond} condition lines')\n",
    "\n",
    "    return output_path\n",
    "\n",
    "    \n",
    "# create function that converts annotations to TextGrid\n",
    "def convert_to_textgrid(patient_path):\n",
    "    '''\n",
    "    This function takes in the file path of the annotated events\n",
    "    and returns a TextGrid file so that we can load it into MFA\n",
    "    '''\n",
    "    file_path = os.path.join(patient_path, 'annotated_events.txt')\n",
    "    from textgrid import TextGrid, IntervalTier\n",
    "    # Load your text file\n",
    "    entries = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            start, end, label = line.strip().split('\\t')\n",
    "            entries.append((float(start), float(end), label))\n",
    "\n",
    "    # Create a TextGrid object and an interval tier\n",
    "    tg = TextGrid()\n",
    "    tier = IntervalTier(name='words')\n",
    "\n",
    "    # Add intervals from your text file to the tier\n",
    "    for start, end, label in entries:\n",
    "        tier.add(start, end, label)\n",
    "\n",
    "    # Add the tier to the TextGrid\n",
    "    tg.append(tier)\n",
    "\n",
    "    # Save the TextGrid file\n",
    "    # remove txt from file path\n",
    "    export_path = os.path.join(patient_path, 'allblocks.TextGrid')\n",
    "    tg.write(f'{export_path}')\n",
    "    return f'{export_path}.TextGrid'\n",
    "\n",
    "\n",
    "# create function that extracts annotations from TextGrid\n",
    "def extract_annotations(patient_path):\n",
    "    '''\n",
    "    This function takes in a file path and extracts the annotations from the TextGrid\n",
    "    The outputs are two files, one for words and one for phones\n",
    "    '''\n",
    "    from textgrid import TextGrid\n",
    "    # Load your TextGrid file\n",
    "    file_path = os.path.join(patient_path, 'output_mfa/allblocks.TextGrid')\n",
    "    tg = TextGrid.fromFile(f'{file_path}')\n",
    "\n",
    "    # Specify the tier names you want to extract intervals from\n",
    "    tier_names = ['words', 'phones']  # Adjust this to match the tier names in your TextGrid\n",
    "\n",
    "\n",
    "    for tier_name in tier_names:\n",
    "        # Find the correct tier\n",
    "        for tier in tg.tiers:\n",
    "            if tier.name == tier_name:\n",
    "                selected_tier = tier\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(\"Tier named '{}' not found.\".format(tier_name))\n",
    "\n",
    "        # Open a text file to write the intervals\n",
    "        # add file path to the tier name\n",
    "        export_mfa_path = os.path.join(patient_path, f'mfa_{tier_name.lower()}.txt')\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            # Write the intervals for the tier\n",
    "            for interval in selected_tier:\n",
    "                start = interval.minTime\n",
    "                end = interval.maxTime\n",
    "                label = interval.mark\n",
    "                # Write the start time, end time, and label separated by tabs\n",
    "                file.write(f'{start}\\t{end}\\t{label}\\n')\n",
    "    return f'{export_mfa_path}_words.txt', f'{export_mfa_path}_phones.txt'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dear reader, \n",
    "\n",
    "### MFA needs two folders two operate, one is input_mfa, and the other is ouput_mfa. Within input_mfa there should be a wav file named allblocks (name is modifiable), and another textGrid folder named allblocks too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_mfa(participant_path):\n",
    "\n",
    "    # Paths for the new subdirectories\n",
    "    input_mfa_path = os.path.join(participant_path, 'input_mfa')\n",
    "    output_mfa_path = os.path.join(participant_path, 'output_mfa')\n",
    "\n",
    "    # Create the 'input_mfa' and 'output_mfa' directories if they don't exist\n",
    "    os.makedirs(input_mfa_path, exist_ok=True)\n",
    "    os.makedirs(output_mfa_path, exist_ok=True)\n",
    "\n",
    "    # Path to the 'allblocks.wav' and 'allblocks.TextGrid' files in the participant's folder\n",
    "    allblocks_wav = os.path.join(participant_path, 'allblocks.wav')\n",
    "    allblocks_textgrid = os.path.join(participant_path, 'allblocks.TextGrid')\n",
    "\n",
    "    # Copy 'allblocks.wav' and 'allblocks.TextGrid' to 'input_mfa' if they exist\n",
    "    if os.path.isfile(allblocks_wav):\n",
    "        shutil.copy(allblocks_wav, input_mfa_path)\n",
    "    if os.path.isfile(allblocks_textgrid):\n",
    "        shutil.copy(allblocks_textgrid, input_mfa_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_mfa(patient_path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes in the file path of the participant and runs MFA on the participant's data.\n",
    "    \"\"\"\n",
    "    # Paths to the input_mfa and output_mfa directories\n",
    "    input_mfa_path = os.path.join(patient_path, 'input_mfa')\n",
    "    output_mfa_path = os.path.join(patient_path, 'output_mfa')\n",
    "\n",
    "    # clear the output_mfa directory\n",
    "\n",
    "    \n",
    "    # Command to activate conda environment\n",
    "    activate_env_command = \"conda activate aligner\"\n",
    "    \n",
    "    # Command to run Montreal Forced Aligner\n",
    "    mfa_command = f\"mfa align --clean {input_mfa_path} english_us_mfa english_mfa {output_mfa_path}\"\n",
    "    \n",
    "    # Execute the commands\n",
    "    try:\n",
    "        # Activate the conda environment\n",
    "        subprocess.run(activate_env_command, shell=True, check=True)\n",
    "        \n",
    "        # Run the MFA align command\n",
    "        subprocess.run(mfa_command, shell=True, check=True)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while running MFA: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pattern = re.compile(r'^D\\d+$')\n",
    "counter = 0\n",
    "for item in os.listdir(root_directory):\n",
    "    patient_path = os.path.join(root_directory, item)\n",
    "\n",
    "    if os.path.isdir(patient_path) and pattern.match(item):\n",
    "        counter += 1\n",
    "print(f'The number of patients in the test folder is {counter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whether you want to run the MFA on a whole directory of patients or rather a few of them, run the code below. Respond to the prompt with yes if the latter, and otherwise if the former. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = 'D21, D33, D55, D23, D22'\n",
    "patients = patients.strip().split(',')\n",
    "print(f'The patients in the test folder are {patients}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanna_run_this = input('Do you want to run the pipeline on specific patients? (yes/no): ')\n",
    "if wanna_run_this == 'yes':\n",
    "    patients = input('Enter the patients you want to run the pipeline on separated by a comma and NO SPACES: ')\n",
    "    patients = patients.strip().split(',')\n",
    "    start = time.time()\n",
    "    for patient in tqdm(patients, desc='Running MFA', ascii=False, ncols=1000, bar_format='{l_bar}{bar}{r_bar}'):\n",
    "        patient_path = os.path.join(root_directory, patient)\n",
    "        print(f'Running MFA for patient {patient}')\n",
    "        annotate(patient_path)\n",
    "        convert_to_textgrid(patient_path)\n",
    "        prepare_for_mfa(patient_path)\n",
    "        run_mfa(patient_path)\n",
    "        extract_annotations(patient_path)\n",
    "    end = time.time()\n",
    "    dur = end - start\n",
    "    if dur < 60:\n",
    "        print(f'The time taken to run the entire pipeline is for the selected patients is {dur} seconds')\n",
    "    elif dur >= 60 and dur < 3600:\n",
    "        print(f'The time taken to run the entire pipeline is for the selected patients is {dur/60} minutes')\n",
    "    else:\n",
    "        print(f'The time taken to run the entire pipeline is for the selected patients is {dur/3600} hours')\n",
    "\n",
    "else:\n",
    "    # run the pipeline on all patients\n",
    "    start = time.time()\n",
    "    for item in tqdm(os.listdir(root_directory), desc= 'Running MFA', ascii=False, ncols=1000, bar_format='{l_bar}{bar}{r_bar}'):\n",
    "        patient_path = os.path.join(root_directory, item)\n",
    "\n",
    "        if os.path.isdir(patient_path) and pattern.match(item):\n",
    "            print(f'Running MFA for patient {item}')\n",
    "            annotate(patient_path)\n",
    "            convert_to_textgrid(patient_path)\n",
    "            prepare_for_mfa(patient_path)\n",
    "            run_mfa(patient_path)\n",
    "            extract_annotations(patient_path)\n",
    "        print(f'MFA for patient {item} has been completed')\n",
    "    end = time.time()\n",
    "    dur = end - start\n",
    "    if dur < 60:\n",
    "        time_taken = dur\n",
    "        print(f'The time taken to run the entire pipeline is for all patients is {time_taken} seconds')\n",
    "    elif dur >= 60 and dur < 3600:\n",
    "        time_taken = dur/60\n",
    "        print(f'The time taken to run the entire pipeline is for all patients is {time_taken} minutes')\n",
    "    else:\n",
    "        time_taken = dur/3600\n",
    "        print(f'The time taken to run the entire pipeline is for all patients is {time_taken} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3133.5939497947693/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats!!!\n",
    "\n",
    "### Now you have two files, mfa_words and mfa_phones that have the time stamps for start and end of single utterances (words/phonemes). \n",
    "\n",
    "### Please load these to Audacity along with your audio file to see the sound-word or sound-phoneme alignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
